import os
import urllib.parse
import requests
import joblib
import numpy as np
import pandas as pd
import warnings  # ThÃªm Ä‘á»ƒ táº¯t cáº£nh bÃ¡o

# Táº¯t cáº£nh bÃ¡o cá»¥ thá»ƒ (táº¡m thá»i, chá»‰ cho validation)
warnings.filterwarnings("ignore", category=UserWarning, module="sklearn.utils.validation")

# Import cÃ¡c hÃ m tá»« module tÃ¹y chá»‰nh (giáº£ Ä‘á»‹nh Ä‘Ã£ cÃ³ file url.py vÃ  hyperlink.py)
from hyperlink import external_hyperlink_ratio, null_link, suspicious_form_action
from url import (
    atsign_in_url, count_dot_in_url, dash_in_url, depth_of_url,
    http_in_url, ip_in_url, length_of_url, redirection_in_url,
    sensitive_word_in_url, shorten_url, uppercase_in_url
)

# Danh sÃ¡ch thá»© tá»± features (pháº£i khá»›p vá»›i X.columns trong train - kiá»ƒm tra vÃ  cáº­p nháº­t náº¿u cáº§n)
FEATURE_ORDER = [
    'atsign_in_url', 'count_dot_in_url', 'dash_in_url', 'depth_of_url',
    'http_in_url', 'ip_in_url', 'length_of_url', 'redirection_in_url',
    'sensitive_word_in_url', 'shorten_url', 'uppercase_in_url',
    'external_hyperlink_ratio', 'suspicious_form_action', 'null_link_ratio'
]

# === HÃ€M TRÃCH XUáº¤T Äáº¶C TRÆ¯NG (giá»¯ nguyÃªn) ===
def extract_features(url, html_content=None):
    features = {}

    # === TRÃCH XUáº¤T Äáº¶C TRÆ¯NG Tá»ª URL ===
    features['atsign_in_url'] = 1 if atsign_in_url.has_at_symbol(url) else 0
    features['count_dot_in_url'] = count_dot_in_url.calculate_uf2(url)
    features['dash_in_url'] = 1 if dash_in_url.has_dash_in_domain(url) else 0
    features['depth_of_url'] = depth_of_url.calculate_uf6(url)
    features['http_in_url'] = 1 if http_in_url.is_phishing_by_scheme(url) else 0
    features['ip_in_url'] = 1 if ip_in_url.has_ip_in_domain(url) else 0
    features['length_of_url'] = length_of_url.calculate_uf5(url)
    features['redirection_in_url'] = 1 if redirection_in_url.has_double_slash_in_path(url) else 0
    features['sensitive_word_in_url'] = 1 if sensitive_word_in_url.has_sensitive_word(url) else 0
    features['shorten_url'] = 1 if shorten_url.is_tiny_url(url) else 0
    features['uppercase_in_url'] = 1 if uppercase_in_url.has_uppercase_letter(url) else 0

    # === TRÃCH XUáº¤T Äáº¶C TRÆ¯NG Tá»ª HTML ===
    if html_content:
        try:
            parsed_url = urllib.parse.urlparse(url)
            domain = parsed_url.netloc.lower()

            ratio = external_hyperlink_ratio.GetExternalHyperlinkRatio(html_content, domain)
            form_action = suspicious_form_action.is_suspicious_form_action(html_content)
            null_link_ratio = null_link.null_link_ratio(html_content)

            features['external_hyperlink_ratio'] = ratio
            features['suspicious_form_action'] = 1 if form_action else 0
            features['null_link_ratio'] = null_link_ratio
        except Exception as e:
            print(f"[Lá»—i trÃ­ch xuáº¥t HTML cho {url}]: {e}")
            features['external_hyperlink_ratio'] = 0.0
            features['suspicious_form_action'] = 0
            features['null_link_ratio'] = 0.0
    else:
        print(f"[KhÃ´ng cÃ³ HTML] cho URL: {url}")
        features['external_hyperlink_ratio'] = 0.0
        features['suspicious_form_action'] = 0
        features['null_link_ratio'] = 0.0

    return features

# === HÃ€M CHUYá»‚N DICT THÃ€NH DATAFRAME HOáº¶C ARRAY (sá»­a Ä‘á»ƒ debug vÃ  fallback) ===
def features_to_input(features_dict, model):
    feature_values = [features_dict.get(feat, 0) for feat in FEATURE_ORDER]
    
    # Thá»­ dÃ¹ng DataFrame vá»›i tÃªn cá»™t
    try:
        feature_df = pd.DataFrame([feature_values], columns=FEATURE_ORDER)
        
        # Debug: Kiá»ƒm tra náº¿u model cÃ³ feature_names_in_ (sklearn >=1.0)
        if hasattr(model, 'feature_names_in_'):
            expected_names = model.feature_names_in_
            if list(feature_df.columns) != list(expected_names):
                print(f"âš ï¸ Cáº£nh bÃ¡o: TÃªn cá»™t predict ({feature_df.columns.tolist()}) khÃ´ng khá»›p train ({expected_names.tolist()}). Sá»­ dá»¥ng array fallback.")
                return np.array(feature_values).reshape(1, -1)
        
        print("âœ… TÃªn cá»™t khá»›p, sá»­ dá»¥ng DataFrame.")
        return feature_df
    except Exception as e:
        print(f"âŒ Lá»—i táº¡o DataFrame: {e}. Sá»­ dá»¥ng array fallback.")
        return np.array(feature_values).reshape(1, -1)

# === HÃ€M FETCH HTML Tá»ª URL (giá»¯ nguyÃªn) ===
def get_html_content(url):
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        response = requests.get(url, timeout=10, headers=headers)
        if response.status_code == 200:
            return response.text
        else:
            print(f"Lá»—i: MÃ£ tráº¡ng thÃ¡i HTTP {response.status_code}")
            return None
    except Exception as e:
        print(f"Lá»—i káº¿t ná»‘i: {str(e)}")
        return None

# === HÃ€M Dá»° ÄOÃN (sá»­a Ä‘á»ƒ nháº­n input linh hoáº¡t) ===
def predict_phishing(model, features_input):
    prediction = model.predict(features_input)[0]
    probabilities = model.predict_proba(features_input)[0]
    
    label = "Phishing (1)" if prediction == 1 else "Benign (0)"
    prob_phishing = probabilities[1]
    prob_benign = probabilities[0]
    
    return prediction, label, prob_phishing, prob_benign

# === CHÆ¯Æ NG TRÃŒNH CHÃNH ===
if __name__ == "__main__":
    # Load mÃ´ hÃ¬nh
    try:
        model = joblib.load("rf_phishing_model.pkl")
        print("âœ… ÄÃ£ load mÃ´ hÃ¬nh Random Forest.")
        
        # Debug: In expected feature names náº¿u cÃ³
        if hasattr(model, 'feature_names_in_'):
            print(f"ğŸ“‹ TÃªn Ä‘áº·c trÆ°ng tá»« model: {model.feature_names_in_.tolist()}")
        else:
            print("ğŸ“‹ Model khÃ´ng lÆ°u tÃªn Ä‘áº·c trÆ°ng (sklearn cÅ©). Äáº£m báº£o FEATURE_ORDER Ä‘Ãºng.")
            
    except FileNotFoundError:
        print("âŒ KhÃ´ng tÃ¬m tháº¥y file model 'rf_phishing_model.pkl'. HÃ£y cháº¡y script train trÆ°á»›c!")
        exit()
    except Exception as e:
        print(f"âŒ Lá»—i load model: {e}")
        exit()
    
    url = input("Nháº­p URL cá»§a website: ").strip()
    if not url:
        print("URL khÃ´ng Ä‘Æ°á»£c Ä‘á»ƒ trá»‘ng!")
        exit()
    
    # ThÃªm scheme náº¿u thiáº¿u
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    print(f"Äang fetch HTML tá»«: {url}")
    html_content = get_html_content(url)
    
    features_dict = extract_features(url, html_content)
    features_input = features_to_input(features_dict, model)
    
    print("\n=== CÃC Äáº¶C TRÆ¯NG TRÃCH XUáº¤T ===")
    for key, value in features_dict.items():
        print(f"{key}: {value}")
    
    # Dá»± Ä‘oÃ¡n
    prediction, label, prob_phishing, prob_benign = predict_phishing(model, features_input)
    
    print("\n=== Káº¾T QUáº¢ Dá»° ÄOÃN ===")
    print(f"NhÃ£n dá»± Ä‘oÃ¡n: {label}")
    print(f"XÃ¡c suáº¥t Benign: {prob_benign:.2%}")
    print(f"XÃ¡c suáº¥t Phishing: {prob_phishing:.2%}")
    
    if prediction == 1:
        print("âš ï¸  Cáº¢NH BÃO: URL nÃ y cÃ³ nguy cÆ¡ cao lÃ  phishing! KhÃ´ng nháº­p thÃ´ng tin cÃ¡ nhÃ¢n.")
    else:
        print("âœ… URL cÃ³ váº» an toÃ n.")